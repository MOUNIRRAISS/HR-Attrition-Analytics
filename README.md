
 
# Welcome to the Portfolio of Raiss Mounir ğŸ“ğŸ“ŠğŸš€ 

### Table of contents
- [About Me ğŸ’¼](#about-me-)
- [Skills and Expertise ğŸš€](#skills-and-expertise-)
- [What You'll Find Here ğŸŒŸ](#what-youll-find-here-)
- [Projects Showcase ğŸš€](#projects-showcase-)
- [Project NÂ°1](#project-nÂ°1)






  
  



### About Me ğŸ’¼

#### Hello! I'm Raiss Mounir, a dedicated Data Analyst and Econometrician with a solid background in economics, data analytics, and applied research. I am passionate about transforming complex datasets into meaningful insights that empower informed decision-making. Holding a Masterâ€™s degree in Applied Econometrics, I excel at leveraging statistical tools and programming languages such as Python, R, SQL and Stata to uncover patterns, design predictive models, and solve real-world problems. Beyond technical expertise, I bring a collaborative mindset, meticulous attention to detail, and a strong commitment to delivering impactful results in every project.

###  Skills and Expertise ğŸš€
- Data Cleaning, Analysis, and Visualization

- Econometric Modeling (Panel Data, Time Series)
 
- Statistical Programming (Python, R, SQL, Stata)

- Predictive Analytics 

- Dashboard Development (Power BI, excel)

###  What You'll Find Here ğŸŒŸ
This portfolio showcases my projects, skills, and achievements, including:

ğŸ“Š Interactive dashboards for visualizing key trends and metrics.

ğŸ“ˆ Advanced econometric models for real-world problem-solving.


### Projects Showcase ğŸš€

Here are some of the key projects Iâ€™ve worked on, highlighting my skills in data analysis, econometrics, and visualization. Each project tackles a unique challenge and demonstrates my ability to transform data into actionable insights:
.














  
### Project NÂ°1


**Title:**  HR Attrition Analysis Dashboard

**Description:**

This project focuses on analyzing employee attrition to help HR teams identify key drivers of employee turnover. Using an interactive dashboard, the project visualizes critical metrics such as attrition rates by department, age group, and job role, empowering decision-makers with actionable insights.

**Technologies Used:** 

- Python for data cleaning and visualisation
- Power BI for dashboard creation.

**Data Source:**  
The data used for this project is sourced from the [Kaggle HR Analytics Dataset](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset).

### Python - Data Cleaning & Visualization 
**Step 1**: Importing Necessary Packages

The first step in any data analysis project is to import the necessary packages or libraries. These libraries provide the functions and tools needed to manipulate the data, perform computations, and create visualizations. Below is the code I used to import the required packages for this project:

![image](https://github.com/user-attachments/assets/2cb3f92b-eadf-43f4-8037-44612a090145)

 **Step 2**: Importing the Dataset ğŸ“Š
 
The next step is to import the dataset into our Python environment. This is done using the pandas library, which allows us to easily load and manipulate data. Below is the code I used to import the dataset and display the first few rows for a quick preview.


![image](https://github.com/user-attachments/assets/8cfd8fd7-1ee6-438e-a270-f38f56699f98)

##### output 

![image](https://github.com/user-attachments/assets/353dd663-09c2-4164-be01-4b6aafe51560)

**Step 3**: Verifying the Dataset ğŸ§

After importing the dataset, it's important to verify its structure and understand the types of data it contains. We can do this using the info() function in pandas, which provides details about the dataset, such as the number of entries, column names, data types, and the presence of missing values.

![image](https://github.com/user-attachments/assets/b7709037-80c1-4d09-a208-b7440a32584a)

##### output 

![image](https://github.com/user-attachments/assets/6027d574-48d0-4e16-92cc-1abb4a55460c)

**Step 4**: Checking for Duplicates ğŸ”

In data analysis, it's crucial to check for duplicate entries, as they can skew your results. To ensure the integrity of the dataset, we use the duplicated() function to identify any duplicate rows.


![image](https://github.com/user-attachments/assets/23660a78-47e6-409c-bec7-cb44a708de89)


